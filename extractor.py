#!/usr/bin/env python3
"""
æ–‡æ¡ˆç»“æ„åŒ–æç‚¼å·¥å…·
ä»æ–‡æ¡ˆä¸­æå–æ€ç»´æ¨¡å‹ã€æ–¹æ³•è®ºå’Œè¯­è¨€é£æ ¼ï¼Œç”Ÿæˆ Lisp æ ¼å¼çš„æ™ºèƒ½ä½“å‡½æ•°
"""

import os
import sys
import json
import argparse
import logging
from pathlib import Path
from datetime import datetime
from typing import Optional, Dict, Any


class ContentExtractor:
    """æ–‡æ¡ˆç»“æ„åŒ–æå–å™¨"""
    
    def __init__(self, config_path: str = "config.json"):
        """åˆå§‹åŒ–æå–å™¨"""
        self.config = self._load_config(config_path)
        self._setup_logging()
        self.client = None
        
    def _load_config(self, config_path: str) -> Dict[str, Any]:
        """åŠ è½½é…ç½®æ–‡ä»¶"""
        config_file = Path(__file__).parent / config_path
        if not config_file.exists():
            raise FileNotFoundError(f"é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {config_file}")
        
        with open(config_file, 'r', encoding='utf-8') as f:
            return json.load(f)
    
    def _setup_logging(self):
        """è®¾ç½®æ—¥å¿—"""
        log_config = self.config.get('logging', {})
        level = getattr(logging, log_config.get('level', 'INFO'))
        
        handlers = []
        if log_config.get('console', True):
            handlers.append(logging.StreamHandler())
        if log_config.get('file'):
            log_file = Path(__file__).parent / log_config['file']
            handlers.append(logging.FileHandler(log_file, encoding='utf-8'))
        
        logging.basicConfig(
            level=level,
            format='%(asctime)s - %(levelname)s - %(message)s',
            handlers=handlers
        )
        self.logger = logging.getLogger(__name__)
    
    def _init_llm_client(self, provider: Optional[str] = None):
        """åˆå§‹åŒ– LLM å®¢æˆ·ç«¯"""
        if provider is None:
            provider = self.config['llm']['provider']
        
        if provider == 'openai':
            return self._init_openai_client()
        elif provider == 'anthropic':
            return self._init_anthropic_client()
        elif provider == 'deepseek':
            return self._init_deepseek_client()
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„ LLM æä¾›å•†: {provider}")
    
    def _init_openai_client(self):
        """åˆå§‹åŒ– OpenAI å®¢æˆ·ç«¯"""
        try:
            from openai import OpenAI
        except ImportError:
            raise ImportError("è¯·å®‰è£… openai åº“: pip install openai")
        
        api_key_env = self.config['llm'].get('api_key_env', 'OPENAI_API_KEY')
        api_key = os.getenv(api_key_env)
        if not api_key:
            raise ValueError(f"æœªè®¾ç½®ç¯å¢ƒå˜é‡: {api_key_env}")
        
        return OpenAI(api_key=api_key)
    
    def _init_anthropic_client(self):
        """åˆå§‹åŒ– Anthropic å®¢æˆ·ç«¯"""
        try:
            from anthropic import Anthropic
        except ImportError:
            raise ImportError("è¯·å®‰è£… anthropic åº“: pip install anthropic")
        
        provider_config = self.config['llm']['alternative_providers']['anthropic']
        api_key_env = provider_config.get('api_key_env', 'ANTHROPIC_API_KEY')
        api_key = os.getenv(api_key_env)
        if not api_key:
            raise ValueError(f"æœªè®¾ç½®ç¯å¢ƒå˜é‡: {api_key_env}")
        
        return Anthropic(api_key=api_key)
    
    def _init_deepseek_client(self):
        """åˆå§‹åŒ– DeepSeek å®¢æˆ·ç«¯"""
        try:
            from openai import OpenAI
        except ImportError:
            raise ImportError("è¯·å®‰è£… openai åº“: pip install openai")
        
        provider_config = self.config['llm']['alternative_providers']['deepseek']
        api_key_env = provider_config.get('api_key_env', 'DEEPSEEK_API_KEY')
        api_key = os.getenv(api_key_env)
        if not api_key:
            raise ValueError(f"æœªè®¾ç½®ç¯å¢ƒå˜é‡: {api_key_env}")
        
        base_url = provider_config.get('base_url')
        return OpenAI(api_key=api_key, base_url=base_url)
    
    def _load_prompt_template(self) -> str:
        """åŠ è½½æç¤ºè¯æ¨¡æ¿"""
        template_path = Path(__file__).parent / self.config['extraction']['prompt_template']
        if not template_path.exists():
            raise FileNotFoundError(f"æç¤ºè¯æ¨¡æ¿ä¸å­˜åœ¨: {template_path}")
        
        with open(template_path, 'r', encoding='utf-8') as f:
            return f.read()
    
    def _read_input_content(self, input_source: Optional[str]) -> str:
        """è¯»å–è¾“å…¥æ–‡æ¡ˆ"""
        if input_source is None or input_source == '-':
            # ä»æ ‡å‡†è¾“å…¥è¯»å–
            self.logger.info("ä»æ ‡å‡†è¾“å…¥è¯»å–æ–‡æ¡ˆ...")
            content = sys.stdin.read()
        else:
            # ä»æ–‡ä»¶è¯»å–
            input_file = Path(input_source)
            if not input_file.exists():
                raise FileNotFoundError(f"è¾“å…¥æ–‡ä»¶ä¸å­˜åœ¨: {input_file}")
            
            self.logger.info(f"ä»æ–‡ä»¶è¯»å–æ–‡æ¡ˆ: {input_file}")
            with open(input_file, 'r', encoding='utf-8') as f:
                content = f.read()
        
        # éªŒè¯å†…å®¹é•¿åº¦
        min_length = self.config['extraction'].get('min_content_length', 100)
        if len(content.strip()) < min_length:
            raise ValueError(f"æ–‡æ¡ˆå†…å®¹è¿‡çŸ­ï¼ˆå°‘äº {min_length} å­—ç¬¦ï¼‰")
        
        return content.strip()
    
    def _call_llm(self, prompt: str, provider: Optional[str] = None) -> str:
        """è°ƒç”¨ LLM API"""
        if provider is None:
            provider = self.config['llm']['provider']
        
        self.logger.info(f"è°ƒç”¨ {provider} API...")
        
        if provider == 'anthropic':
            return self._call_anthropic(prompt)
        else:
            return self._call_openai_compatible(prompt, provider)
    
    def _call_anthropic(self, prompt: str) -> str:
        """è°ƒç”¨ Anthropic API"""
        if self.client is None:
            self.client = self._init_llm_client('anthropic')
        
        provider_config = self.config['llm']['alternative_providers']['anthropic']
        
        response = self.client.messages.create(
            model=provider_config['model'],
            max_tokens=provider_config['max_tokens'],
            messages=[
                {"role": "user", "content": prompt}
            ]
        )
        
        return response.content[0].text
    
    def _call_openai_compatible(self, prompt: str, provider: str) -> str:
        """è°ƒç”¨ OpenAI å…¼å®¹çš„ API"""
        if self.client is None:
            self.client = self._init_llm_client(provider)
        
        if provider == 'openai':
            model = self.config['llm']['model']
            max_tokens = self.config['llm']['max_tokens']
            temperature = self.config['llm'].get('temperature', 0.7)
        else:
            provider_config = self.config['llm']['alternative_providers'][provider]
            model = provider_config['model']
            max_tokens = provider_config['max_tokens']
            temperature = provider_config.get('temperature', 0.7)
        
        response = self.client.chat.completions.create(
            model=model,
            messages=[
                {"role": "user", "content": prompt}
            ],
            max_tokens=max_tokens,
            temperature=temperature
        )
        
        return response.choices[0].message.content
    
    def _extract_lisp_code(self, response: str) -> str:
        """ä»å“åº”ä¸­æå– Lisp ä»£ç """
        # å°è¯•æå–ä»£ç å—
        if "```lisp" in response:
            start = response.find("```lisp") + 7
            end = response.find("```", start)
            if end != -1:
                return response[start:end].strip()
        
        # å¦‚æœæ²¡æœ‰ä»£ç å—æ ‡è®°ï¼Œè¿”å›æ•´ä¸ªå“åº”
        return response.strip()
    
    def _save_output(self, content: str, output_path: Optional[str] = None) -> str:
        """ä¿å­˜è¾“å‡ºç»“æœ"""
        output_config = self.config['output']
        
        if output_path is None:
            # ç”Ÿæˆé»˜è®¤è¾“å‡ºè·¯å¾„
            output_dir = Path(__file__).parent / output_config['directory']
            output_dir.mkdir(exist_ok=True)
            
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            prefix = output_config['filename_prefix']
            suffix = output_config['filename_suffix']
            filename = f"{prefix}_{timestamp}{suffix}"
            output_path = output_dir / filename
        else:
            output_path = Path(output_path)
        
        # æ£€æŸ¥æ˜¯å¦è¦†ç›–
        if output_path.exists() and not output_config.get('overwrite', False):
            raise FileExistsError(f"è¾“å‡ºæ–‡ä»¶å·²å­˜åœ¨: {output_path}ï¼Œä½¿ç”¨ --overwrite å¼ºåˆ¶è¦†ç›–")
        
        # ä¿å­˜æ–‡ä»¶
        with open(output_path, 'w', encoding=output_config['encoding']) as f:
            f.write(content)
        
        self.logger.info(f"ç»“æœå·²ä¿å­˜åˆ°: {output_path}")
        return str(output_path)
    
    def extract(self, 
                input_source: Optional[str] = None,
                output_path: Optional[str] = None,
                provider: Optional[str] = None) -> str:
        """
        æ‰§è¡Œæå–æµç¨‹
        
        Args:
            input_source: è¾“å…¥æ–‡ä»¶è·¯å¾„ï¼ŒNone æˆ– '-' è¡¨ç¤ºä»æ ‡å‡†è¾“å…¥è¯»å–
            output_path: è¾“å‡ºæ–‡ä»¶è·¯å¾„ï¼ŒNone è¡¨ç¤ºè‡ªåŠ¨ç”Ÿæˆ
            provider: LLM æä¾›å•†ï¼ŒNone è¡¨ç¤ºä½¿ç”¨é…ç½®æ–‡ä»¶ä¸­çš„é»˜è®¤å€¼
        
        Returns:
            è¾“å‡ºæ–‡ä»¶è·¯å¾„
        """
        try:
            # 1. è¯»å–è¾“å…¥å†…å®¹
            content = self._read_input_content(input_source)
            self.logger.info(f"æˆåŠŸè¯»å–æ–‡æ¡ˆï¼Œé•¿åº¦: {len(content)} å­—ç¬¦")
            
            # 2. åŠ è½½æç¤ºè¯æ¨¡æ¿
            template = self._load_prompt_template()
            
            # 3. æ„é€ å®Œæ•´æç¤ºè¯
            prompt = template.replace("{{INPUT_CONTENT}}", content)
            
            # 4. è°ƒç”¨ LLM
            response = self._call_llm(prompt, provider)
            self.logger.info("æˆåŠŸè·å– LLM å“åº”")
            
            # 5. æå– Lisp ä»£ç 
            lisp_code = self._extract_lisp_code(response)
            
            # 6. ä¿å­˜ç»“æœ
            output_file = self._save_output(lisp_code, output_path)
            
            return output_file
            
        except Exception as e:
            self.logger.error(f"æå–å¤±è´¥: {str(e)}")
            raise


def main():
    """å‘½ä»¤è¡Œå…¥å£"""
    parser = argparse.ArgumentParser(
        description='æ–‡æ¡ˆç»“æ„åŒ–æç‚¼å·¥å…· - å°†æ–‡æ¡ˆè½¬æ¢ä¸º Lisp æ ¼å¼çš„æ™ºèƒ½ä½“å‡½æ•°',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹ç”¨æ³•:
  # ä»æ–‡ä»¶æå–
  python extractor.py -i input.txt -o output.lisp
  
  # ä»æ ‡å‡†è¾“å…¥æå–
  cat input.txt | python extractor.py -o output.lisp
  
  # ä½¿ç”¨ä¸åŒçš„ LLM æä¾›å•†
  python extractor.py -i input.txt --provider anthropic
  
  # ä½¿ç”¨è‡ªå®šä¹‰é…ç½®æ–‡ä»¶
  python extractor.py -i input.txt --config my_config.json
        """
    )
    
    parser.add_argument(
        '-i', '--input',
        help='è¾“å…¥æ–‡ä»¶è·¯å¾„ï¼ˆä¸æŒ‡å®šæˆ–ä½¿ç”¨ - è¡¨ç¤ºä»æ ‡å‡†è¾“å…¥è¯»å–ï¼‰',
        default=None
    )
    
    parser.add_argument(
        '-o', '--output',
        help='è¾“å‡ºæ–‡ä»¶è·¯å¾„ï¼ˆä¸æŒ‡å®šåˆ™è‡ªåŠ¨ç”Ÿæˆï¼‰',
        default=None
    )
    
    parser.add_argument(
        '-c', '--config',
        help='é…ç½®æ–‡ä»¶è·¯å¾„ï¼ˆé»˜è®¤: config.jsonï¼‰',
        default='config.json'
    )
    
    parser.add_argument(
        '-p', '--provider',
        help='LLM æä¾›å•†ï¼ˆopenai/anthropic/deepseekï¼Œé»˜è®¤ä½¿ç”¨é…ç½®æ–‡ä»¶ä¸­çš„è®¾ç½®ï¼‰',
        choices=['openai', 'anthropic', 'deepseek'],
        default=None
    )
    
    parser.add_argument(
        '--overwrite',
        help='å¦‚æœè¾“å‡ºæ–‡ä»¶å·²å­˜åœ¨ï¼Œå¼ºåˆ¶è¦†ç›–',
        action='store_true'
    )
    
    args = parser.parse_args()
    
    try:
        # åˆ›å»ºæå–å™¨
        extractor = ContentExtractor(config_path=args.config)
        
        # å¦‚æœè®¾ç½®äº† overwrite æ ‡å¿—ï¼Œæ›´æ–°é…ç½®
        if args.overwrite:
            extractor.config['output']['overwrite'] = True
        
        # æ‰§è¡Œæå–
        output_file = extractor.extract(
            input_source=args.input,
            output_path=args.output,
            provider=args.provider
        )
        
        print(f"\nâœ… æå–æˆåŠŸï¼")
        print(f"ğŸ“„ è¾“å‡ºæ–‡ä»¶: {output_file}")
        
    except KeyboardInterrupt:
        print("\n\nâš ï¸  ç”¨æˆ·ä¸­æ–­æ“ä½œ")
        sys.exit(1)
    except Exception as e:
        print(f"\nâŒ é”™è¯¯: {str(e)}", file=sys.stderr)
        sys.exit(1)


if __name__ == '__main__':
    main()

